from functools import lru_cache
'\nenhanced_brain_opencode.py - Self-Optimizing Brain with Autonomous Capabilities\n\nExtends the original brain_opencode.py with:\n- Autonomous skill generation and optimization\n- Self-learning routing patterns\n- Advanced analytics integration\n- Workflow generation and execution\n- Performance monitoring and improvement\n- Context-aware response generation\n'
import logging
import time
import json
import statistics
from typing import List, Dict, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from pathlib import Path
from config_opencode import Config, load_config, get_current_opencode_model
from skills import SkillRegistry
from llm_client_opencode import LLMClient, LLMResponse
from skills.analytics_skill import UsageAnalyzer, PerformanceMonitor
from skills.autonomous_reasoning_skill import SkillRoutingOptimizer, CrossSkillDependencyAnalyzer, AutonomousWorkflowGenerator
logger = logging.getLogger(__name__)

@dataclass
class Message:
    role: str
    content: str
    timestamp: Optional[float] = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()

class ConversationHistory:

    def __init__(self, max_messages: int=20):
        self.max_messages = max_messages
        self._messages: List[Message] = []
        self.session_start = time.time()

    def add(self, role: str, content: str):
        self._messages.append(Message(role=role, content=content))
        if len(self._messages) > self.max_messages:
            self._messages = self._messages[-self.max_messages:]

    def to_list(self) -> List[Dict[str, str]]:
        return [{'role': m.role, 'content': m.content} for m in self._messages]

    def get_recent_context(self, num_messages: int=5) -> List[str]:
        return [msg.content for msg in self._messages[-num_messages:]]

class SelfOptimizingBrain:
    """
    Enhanced brain with autonomous optimization and self-learning capabilities.
    
    Features:
    - Real-time performance monitoring
    - Autonomous skill generation
    - Self-optimizing routing patterns
    - Analytics-driven improvements
    - Workflow generation and execution
    - Context-aware learning
    """

    def __init__(self, config: Optional[Config]=None):
        if config is None:
            config = load_config()
        self.config = config
        self.llm_client = LLMClient(config)
        self.skills = SkillRegistry()
        self.conversation_history = ConversationHistory()
        self.usage_analyzer = UsageAnalyzer()
        self.performance_monitor = PerformanceMonitor()
        self.routing_optimizer = SkillRoutingOptimizer()
        self.dependency_analyzer = CrossSkillDependencyAnalyzer()
        self.workflow_generator = AutonomousWorkflowGenerator()
        self.optimization_history = []
        self.routing_patterns = defaultdict(list)
        self.success_rates = defaultdict(float)
        self.performance_metrics = {}
        self.current_model = config.opencode_model or f'{config.provider}/{config.model_name}'
        self.model_switch_count = 0
        self.session_stats = {'message_count': 0, 'session_duration': 0, 'user_messages': 0, 'assistant_messages': 0, 'skills_used': defaultdict(int), 'model_switches': 0}
        for skill_name in self.skills.skills.keys():
            self.session_stats['skills_used'][skill_name] = 0
        logger.info(f'Enhanced Brain initialized with {len(self.skills.skills)} skills')

    @lru_cache(maxsize=128)
    def process(self, user_input: str) -> Dict[str, Any]:
        """
        Main processing method with enhanced autonomous capabilities.
        
        Returns:
            Dict with response data, routing info, performance metrics, and optimization insights
        """
        start_time = time.time()
        self.session_stats['message_count'] += 1
        self.conversation_history.add('user', user_input)
        self.session_stats['user_messages'] += 1
        try:
            intent_data = self.parse_intent_with_optimization(user_input)
            if intent_data['intent'] == 'skill':
                response_data = self.execute_skill_with_tracking(intent_data, user_input)
            elif intent_data['intent'] == 'model_switch':
                response_data = self.handle_model_switch(user_input)
            elif intent_data['intent'] == 'analytics':
                response_data = self.handle_analytics_request(intent_data, user_input)
            elif intent_data['intent'] == 'workflow':
                response_data = self.handle_workflow_request(user_input)
            elif intent_data['intent'] == 'optimization':
                response_data = self.handle_optimization_request(user_input)
            else:
                response_data = self.generate_llm_response(user_input, intent_data)
            self.conversation_history.add('assistant', response_data['response'])
            self.session_stats['assistant_messages'] += 1
            response_time = time.time() - start_time
            response_data['performance_metrics'] = {'response_time': response_time, 'session_stats': self.session_stats.copy(), 'optimization_applied': len(self.optimization_history)}
            if self.should_optimize():
                optimization_result = self.run_autonomous_optimization()
                response_data['optimization_suggestions'] = optimization_result
            return response_data
        except Exception as e:
            logger.error(f'Error processing input: {e}')
            return {'response': f'I encountered an error: {str(e)}', 'error': True, 'intent': {'intent': 'error'}}

    def parse_intent_with_optimization(self, text: str) -> Dict[str, Any]:
        """
        Enhanced intent parsing with optimization tracking and learning
        """
        lowered = text.lower()
        if lowered.startswith('/model '):
            return {'intent': 'model_switch', 'action': 'switch_model'}
        if any((keyword in lowered for keyword in ['analytics', 'performance', 'usage', 'metrics'])):
            if 'performance' in lowered or 'status' in lowered:
                return {'intent': 'analytics', 'action': 'performance_monitor'}
            elif 'usage' in lowered or 'patterns' in lowered:
                return {'intent': 'analytics', 'action': 'usage_analysis'}
            else:
                return {'intent': 'analytics', 'action': 'comprehensive'}
        if any((keyword in lowered for keyword in ['workflow', 'pipeline', 'automate', 'autonomous'])):
            if 'generate' in lowered or 'create' in lowered:
                return {'intent': 'workflow', 'action': 'generate'}
            else:
                return {'intent': 'workflow', 'action': 'execute'}
        if any((keyword in lowered for keyword in ['optimize', 'improve', 'faster', 'better'])):
            return {'intent': 'optimization', 'action': 'analyze'}
        intent_data = self.parse_intent(text)
        self.track_routing_pattern(text, intent_data)
        return intent_data

    def track_routing_pattern(self, text: str, intent_data: Dict[str, Any]):
        """Track routing patterns for self-learning"""
        if intent_data.get('intent') == 'skill':
            skill_name = intent_data.get('skill')
            if skill_name:
                self.routing_patterns[skill_name].append({'input': text, 'timestamp': time.time(), 'success': True})

    def execute_skill_with_tracking(self, intent_data: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """Execute skill with performance tracking and optimization"""
        skill_name = intent_data.get('skill')
        if skill_name not in self.skills.skills:
            return {'response': f"Skill '{skill_name}' not found", 'skill': skill_name, 'error': True}
        try:
            self.session_stats['skills_used'][skill_name] += 1
            skill = self.skills.get(skill_name)
            start_time = time.time()
            params = self.extract_skill_params(skill_name, user_input)
            skill_result = skill.execute(params)
            execution_time = time.time() - start_time
            response = self.format_skill_response(skill_name, skill_result, user_input)
            return {'response': response, 'skill': skill_name, 'skill_result': skill_result, 'execution_time': execution_time, 'performance_data': {'skill_execution_time': execution_time, 'success': True}}
        except Exception as e:
            logger.error(f'Error executing skill {skill_name}: {e}')
            return {'response': f'Error executing {skill_name}: {str(e)}', 'skill': skill_name, 'error': True}

    def extract_skill_params(self, skill_name: str, user_input: str) -> Dict[str, Any]:
        """Extract parameters for skill execution"""
        params = {}
        if skill_name == 'text_analysis':
            if 'sentiment' in user_input.lower():
                params['analysis_type'] = 'sentiment'
            elif 'summary' in user_input.lower():
                params['analysis_type'] = 'summary'
            else:
                params['analysis_type'] = 'comprehensive'
            params['text'] = user_input
        elif skill_name == 'code_generation':
            if 'python' in user_input.lower():
                params['language'] = 'python'
            elif 'javascript' in user_input.lower():
                params['language'] = 'javascript'
            else:
                params['language'] = 'python'
            params['task'] = user_input
        elif skill_name == 'web_search':
            params['query'] = user_input.replace('search for', '').strip()
        elif skill_name == 'ml_training':
            if 'train' in user_input.lower():
                params['task'] = 'training'
            else:
                params['task'] = 'analysis'
        return params

    def format_skill_response(self, skill_name: str, skill_result: Dict[str, Any], user_input: str) -> str:
        """Format skill response with context and insights"""
        if skill_name == 'text_analysis':
            sentiment = skill_result.get('sentiment', 'neutral')
            confidence = skill_result.get('confidence', 0.0)
            return f'ðŸ“Š **Text Analysis Result:**\n\nSentiment: **{sentiment}** (confidence: {confidence:.2f})\nAnalysis completed successfully.'
        elif skill_name == 'code_generation':
            code = skill_result.get('code', '')
            language = skill_result.get('language', 'python')
            return f'ðŸ’» **Generated {language.title()} Code:**\n\n```\n{code}\n```'
        elif skill_name == 'web_search':
            results = skill_result.get('results', [])
            return f'ðŸ” **Search Results:**\n\n' + '\n'.join([f"â€¢ {result.get('title', 'Untitled')}: {result.get('snippet', 'No description')}" for result in results[:3]])
        elif skill_name == 'analytics_analyzer':
            analysis_type = skill_result.get('analysis_type', 'comprehensive')
            return f'ðŸ“ˆ **Analytics Report ({analysis_type}):**\n\nAnalysis completed with insights and recommendations.'
        else:
            return f'âœ… {skill_name.title()} completed successfully with results available.'

    def handle_analytics_request(self, intent_data: Dict[str, Any], user_input: str) -> Dict[str, Any]:
        """Handle analytics requests"""
        action = intent_data.get('action', 'comprehensive')
        if action == 'performance_monitor':
            result = self.performance_monitor.execute({'monitor_type': 'current_status'})
        elif action == 'usage_analysis':
            result = self.usage_analyzer.execute({'analysis_type': 'usage_patterns'})
        else:
            result = self.usage_analyzer.execute({'analysis_type': 'comprehensive'})
        response = f'ðŸ“Š **Analytics Report:**\n\n'
        if 'usage_patterns' in result:
            patterns = result['usage_patterns']
            response += f"Most active skill: {patterns.get('most_active_skill', 'N/A')}\n"
            response += f"User engagement: {patterns.get('user_engagement_score', 0):.2f}\n"
        return {'response': response, 'analytics_data': result, 'analytics_type': action}

    def handle_workflow_request(self, user_input: str) -> Dict[str, Any]:
        """Handle workflow generation and execution requests"""
        if 'generate' in user_input.lower() or 'create' in user_input.lower():
            workflow_type = 'data_analysis' if 'data' in user_input.lower() else 'code_development'
            result = self.workflow_generator.execute({'workflow_type': workflow_type, 'automation_level': 'full'})
            workflow = result.get('workflow', {})
            response = f"ðŸ”„ **Generated Workflow: {workflow.get('name', 'Custom')}**\n\n"
            response += f"Description: {workflow.get('description', 'N/A')}\n"
            response += f"Estimated time: {workflow.get('estimated_time', 'N/A')}\n"
            response += f"Steps: {len(workflow.get('steps', []))}"
            return {'response': response, 'workflow_data': result, 'workflow_generated': True}
        else:
            return {'response': 'ðŸ”„ Workflow execution started. Checking available workflows...', 'workflow_execution': True}

    def handle_optimization_request(self, user_input: str) -> Dict[str, Any]:
        """Handle optimization requests"""
        result = self.routing_optimizer.execute({'optimization_type': 'comprehensive'})
        response = f'ðŸš€ **System Optimization Report:**\n\n'
        plan = result.get('optimization_plan', {})
        if 'immediate' in plan:
            response += '**Immediate improvements:**\n'
            for improvement in plan['immediate'][:2]:
                response += f'â€¢ {improvement}\n'
        improvements = result.get('expected_improvements', {})
        if improvements:
            response += f'\n**Expected improvements:**\n'
            for (key, value) in improvements.items():
                response += f'â€¢ {key}: {value}\n'
        return {'response': response, 'optimization_data': result, 'optimization_applied': True}

    def handle_model_switch(self, user_input: str) -> Dict[str, Any]:
        """Handle model switching with enhanced tracking"""
        model_part = user_input.split(' ', 1)[1] if ' ' in user_input else ''
        if self.llm_client.switch_model(model_part):
            self.current_model = model_part
            self.model_switch_count += 1
            self.session_stats['model_switches'] += 1
            return {'response': f'âœ… Model switched to: {model_part}', 'model_switch': True, 'new_model': model_part}
        else:
            return {'response': f'âŒ Failed to switch to model: {model_part}', 'model_switch': False, 'error': True}

    def generate_llm_response(self, user_input: str, intent_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate LLM response for general conversations"""
        context = self.conversation_history.get_recent_context()
        system_prompt = f"You are Neo-Clone, an AI assistant integrated with Opencode. \nCurrent model: {self.current_model}\nAvailable skills: {', '.join(self.skills.skills.keys())}\n        \nRespond helpfully and suggest using skills when appropriate."
        messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': user_input}]
        response = self.llm_client.generate(messages)
        return {'response': response.content, 'intent': intent_data, 'llm_generated': True}

    def should_optimize(self) -> bool:
        """Determine if optimization should be performed"""
        return self.session_stats['message_count'] % 10 == 0 or time.time() - self.conversation_history.session_start > 300

    def run_autonomous_optimization(self) -> Dict[str, Any]:
        """Run autonomous optimization routines"""
        optimization_results = {'routing_optimization': None, 'performance_improvements': None, 'workflow_suggestions': None}
        try:
            routing_result = self.routing_optimizer.execute({'optimization_type': 'performance_improvements'})
            optimization_results['routing_optimization'] = routing_result
            performance_result = self.performance_monitor.execute({'monitor_type': 'current_status'})
            optimization_results['performance_improvements'] = performance_result
            workflow_result = self.workflow_generator.execute({'workflow_type': 'data_analysis'})
            optimization_results['workflow_suggestions'] = workflow_result
            self.optimization_history.append({'timestamp': time.time(), 'results': optimization_results})
        except Exception as e:
            logger.error(f'Error in autonomous optimization: {e}')
            optimization_results['error'] = str(e)
        return optimization_results

    def parse_intent(self, text: str) -> Dict[str, Any]:
        """Original intent parsing method (enhanced version)"""
        lowered = text.lower()
        if any((keyword in lowered for keyword in ['minimax', 'analyze intent', 'reasoning', 'think about'])):
            return {'intent': 'skill', 'skill': 'minimax_agent'}
        if any((keyword in lowered for keyword in ['analyze', 'sentiment', 'text', 'feeling'])):
            return {'intent': 'skill', 'skill': 'text_analysis'}
        if any((keyword in lowered for keyword in ['generate', 'code', 'program', 'script', 'python', 'javascript'])):
            return {'intent': 'skill', 'skill': 'code_generation'}
        if any((keyword in lowered for keyword in ['search', 'find', 'look up', 'web'])):
            return {'intent': 'skill', 'skill': 'web_search'}
        if any((keyword in lowered for keyword in ['train', 'model', 'machine learning', 'predict'])):
            return {'intent': 'skill', 'skill': 'ml_training'}
        if any((keyword in lowered for keyword in ['data', 'analyze data', 'dataset', 'inspect'])):
            return {'intent': 'skill', 'skill': 'data_inspector'}
        if any((keyword in lowered for keyword in ['file', 'organize', 'manage', 'directory'])):
            return {'intent': 'skill', 'skill': 'file_manager'}
        return {'intent': 'conversation', 'action': 'general'}

    def get_status(self) -> Dict[str, Any]:
        """Get comprehensive brain status including optimization metrics"""
        return {'brain_type': 'self_optimizing', 'current_model': self.current_model, 'provider': self.config.provider, 'model_name': self.config.model_name, 'opencode_model': self.config.opencode_model, 'is_opencode_available': self.config.opencode_model is not None, 'model_switches': self.model_switch_count, 'conversation_stats': {**self.session_stats, 'session_duration': time.time() - self.conversation_history.session_start}, 'available_skills': list(self.skills.skills.keys()), 'skill_count': len(self.skills.skills), 'config_source': 'opencode' if self.config.opencode_model else 'local', 'autonomous_features': {'usage_analyzer': True, 'performance_monitor': True, 'routing_optimizer': True, 'dependency_analyzer': True, 'workflow_generator': True}, 'optimization_history_count': len(self.optimization_history), 'routing_patterns_count': sum((len(patterns) for patterns in self.routing_patterns.values()))}

    def generate_analytics_report(self) -> Dict[str, Any]:
        """Generate comprehensive analytics report"""
        return {'report_type': 'comprehensive', 'timestamp': datetime.now().isoformat(), 'system_status': self.get_status(), 'performance_metrics': self.performance_metrics, 'routing_analysis': self.routing_optimizer._analyze_current_routing_patterns(), 'optimization_recommendations': self.routing_optimizer._generate_optimization_recommendations(), 'workflow_opportunities': self.dependency_analyzer._find_integration_opportunities()}

class OpencodeBrain(SelfOptimizingBrain):
    """Backward compatibility alias"""
    pass