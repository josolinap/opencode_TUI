from functools import lru_cache
'\ndemo_tui.py - Non-interactive demo of Neo-Clone TUI features.\n\nThis script demonstrates the TUI functionality by creating sample interactions\nand showing how the components work together.\n'
import sys
from pathlib import Path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
from config import load_config
from skills import SkillRegistry
from brain import Brain

@lru_cache(maxsize=128)
def demo_brain_interactions():
    """Demonstrate brain interactions without TUI."""
    print('üß† Neo-Clone Brain Engine Demo')
    print('=' * 50)
    config = load_config()
    skills = SkillRegistry()
    brain = Brain(config, skills)
    print('Configuration:')
    print(f'  Provider: {config.provider}')
    print(f'  Model: {config.model_name}')
    print(f'  Max Tokens: {config.max_tokens}')
    print(f'  Temperature: {config.temperature}')
    print(f"\nAvailable Skills: {', '.join(skills.list_skills())}")
    test_cases = [{'input': 'Generate a Python function to calculate fibonacci numbers', 'expected_skill': 'code_generation'}, {'input': 'Analyze the sentiment: I absolutely love this amazing product!', 'expected_skill': 'text_analysis'}, {'input': 'Show me a summary of my sales data', 'expected_skill': 'data_inspector'}, {'input': 'How do I train a recommendation system?', 'expected_skill': 'ml_training'}, {'input': 'Hello, how are you today?', 'expected_skill': None}]
    print('\nüîç Testing Intent Parsing and Skill Routing:')
    print('-' * 50)
    for (i, case) in enumerate(test_cases, 1):
        print(f'''\n{i}. User Input: "{case['input']}"''')
        intent = brain.parse_intent(case['input'])
        print(f'   Intent Detection: {intent}')
        if intent['intent'] == 'skill' and intent.get('skill'):
            skill_name = intent['skill']
            print(f'   Routing to Skill: {skill_name}')
            try:
                result = brain.route_to_skill(skill_name, case['input'])
                print(f"   Skill Result Type: {type(result.get('output', {}))}")
                if skill_name == 'code_generation' and 'output' in result:
                    code = result['output'].get('code', '')
                    if code:
                        print(f'   Generated Code Preview:\n   {code[:100]}...')
            except Exception as e:
                print(f'   Error: {e}')
        else:
            print(f'   Action: LLM Chat (simulated - would call {config.provider} API)')
    print(f'\nüéØ Intent Detection Accuracy:')
    print('-' * 30)
    for case in test_cases:
        intent = brain.parse_intent(case['input'])
        expected = case['expected_skill']
        detected = intent.get('skill') if intent['intent'] == 'skill' else 'LLM'
        status = '‚úÖ' if expected is None and detected == 'LLM' or (expected and detected == expected) else '‚ùå'
        print(f"{status} '{case['input'][:40]}...' ‚Üí {detected}")

def demo_skill_details():
    """Show detailed information about each skill."""
    print(f'\nüîß Skill Details:')
    print('=' * 50)
    skills = SkillRegistry()
    for skill_name in skills.list_skills():
        try:
            skill = skills.get(skill_name)
            print(f'\nüì¶ {skill_name.upper()}')
            print(f'   Description: {skill.description}')
            print(f'   Example Usage: {skill.example_usage}')
            print(f'   Parameters: {skill.parameters}')
            test_result = skill.execute({'text': f'Test input for {skill_name}'})
            print(f'   Test Result Keys: {(list(test_result.keys()) if isinstance(test_result, dict) else type(test_result))}')
        except Exception as e:
            print(f'   ‚ùå Error loading {skill_name}: {e}')

def demo_configuration():
    """Show configuration options."""
    print(f'\n‚öôÔ∏è  Configuration Options:')
    print('=' * 50)
    config = load_config()
    print('Current Settings:')
    for (key, value) in config.model_dump().items():
        print(f'  {key}: {value}')
    print(f'\nEnvironment Variable Mapping:')
    env_vars = {'NEO_PROVIDER': 'Provider selection (ollama, hf, api)', 'NEO_MODEL': 'Model name (e.g., ggml-neural-chat)', 'NEO_API_ENDPOINT': 'API endpoint URL', 'NEO_API_KEY': 'API key for paid services', 'NEO_MAX_TOKENS': 'Maximum response length', 'NEO_TEMPERATURE': 'Generation creativity (0.0-2.0)', 'NEO_SYSTEM_PROMPT': 'Custom system prompt'}
    for (var, desc) in env_vars.items():
        current = '‚úì' if getattr(config, var.replace('NEO_', '').lower(), None) else '‚óã'
        print(f'  {current} {var}: {desc}')

def main():
    """Main demo function."""
    print('üöÄ Neo-Clone TUI Feature Demo')
    print('=' * 60)
    print('This demo showcases the TUI assistant without running the')
    print('interactive interface, showing how all components work together.')
    print('=' * 60)
    demo_brain_interactions()
    demo_skill_details()
    demo_configuration()
    print(f'\nüéâ Demo Complete!')
    print('=' * 50)
    print('To run the actual TUI interface:')
    print('  python main.py --tui')
    print('\nTo run CLI mode:')
    print('  python main.py --cli')
    print('\nTo test everything:')
    print('  python test_tui.py')
if __name__ == '__main__':
    main()