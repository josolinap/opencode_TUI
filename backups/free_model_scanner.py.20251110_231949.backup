from functools import lru_cache
'\nfree_model_scanner.py - Internet scanner for discovering free LLM models\n\nThis module scans various sources to find free LLM models that can be used\nwith Neo-Clone, making the system more self-optimizing and resourceful.\n'
import requests
import json
import re
import time
from typing import List, Dict, Any
from dataclasses import dataclass
import logging
logger = logging.getLogger(__name__)

@dataclass
class FreeModel:
    """Represents a discovered free model"""
    name: str
    provider: str
    description: str
    url: str
    requires_api_key: bool = False
    rate_limit: str = 'Unknown'
    context_window: int = 4096

class FreeModelScanner:
    """Scans the internet for free LLM models"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Neo-Clone-FreeModelScanner/1.0'})

    @lru_cache(maxsize=128)
    def scan_github_models(self) -> List[FreeModel]:
        """Scan GitHub for free/open source models"""
        models = []
        search_queries = ['free language models api', 'open source llm models', 'free ai models api key', 'no cost language models']
        for query in search_queries:
            try:
                url = f'https://api.github.com/search/repositories?q={query}&sort=stars&order=desc'
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    for repo in data.get('items', [])[:5]:
                        if self._is_free_model_repo(repo):
                            model = self._extract_model_from_github_repo(repo)
                            if model:
                                models.append(model)
                time.sleep(1)
            except Exception as e:
                logger.warning(f"Failed to scan GitHub for query '{query}': {e}")
        return models

    def scan_huggingface_free_models(self) -> List[FreeModel]:
        """Scan Hugging Face for free models"""
        models = []
        try:
            url = 'https://huggingface.co/api/models'
            params = {'limit': 20, 'sort': 'downloads', 'direction': '-1'}
            response = self.session.get(url, params=params, timeout=15)
            if response.status_code == 200:
                data = response.json()
                for model_data in data:
                    if self._is_free_huggingface_model(model_data):
                        model = self._extract_model_from_huggingface(model_data)
                        if model:
                            models.append(model)
        except Exception as e:
            logger.warning(f'Failed to scan Hugging Face: {e}')
        return models

    def scan_free_api_providers(self) -> List[FreeModel]:
        """Scan for free API providers"""
        models = []
        free_providers = [{'name': 'Groq', 'models': ['llama3-8b-8192', 'mixtral-8x7b-32768', 'gemma-7b-it'], 'url': 'https://groq.com/', 'requires_api_key': True, 'rate_limit': '30 requests/minute (free tier)'}, {'name': 'Together.ai', 'models': ['meta-llama/Llama-2-7b-chat-hf', 'mistralai/Mistral-7B-Instruct-v0.1'], 'url': 'https://together.ai/', 'requires_api_key': True, 'rate_limit': '1000 requests/day (free tier)'}, {'name': 'Replicate', 'models': ['meta/llama-2-70b-chat', 'mistralai/mixtral-8x7b'], 'url': 'https://replicate.com/', 'requires_api_key': True, 'rate_limit': 'Free credits available'}]
        for provider in free_providers:
            for model_name in provider['models']:
                model = FreeModel(name=f"{provider['name'].lower()}/{model_name}", provider=provider['name'], description=f"Free tier model from {provider['name']}", url=provider['url'], requires_api_key=provider['requires_api_key'], rate_limit=provider['rate_limit'])
                models.append(model)
        return models

    def scan_free_frameworks(self) -> List[FreeModel]:
        """Scan for free AI frameworks and tools"""
        frameworks = []
        free_frameworks = [{'name': 'AutoML-Agent', 'description': 'ICML 2025 paper: Multi-agent LLM framework for full-pipeline AutoML (image, text, tabular, graph, time series)', 'url': 'https://github.com/AutoML-Agent/AutoML-Agent', 'provider': 'GitHub', 'type': 'framework'}, {'name': 'MLE-STAR-Open', 'description': 'Google-free reimplementation of MLE-STAR multi-agent ML engineering pipeline using OpenRouter/DuckDuckGo', 'url': 'https://github.com/yangheng95/MLE-STAR-Open', 'provider': 'GitHub', 'type': 'framework'}, {'name': 'AgentGPT', 'description': 'Web platform for assembling and deploying autonomous AI agents (35k+ stars)', 'url': 'https://github.com/reworkd/AgentGPT', 'provider': 'GitHub', 'type': 'platform'}, {'name': 'CrewAI', 'description': 'Framework for orchestrating role-playing autonomous AI agents (40k+ stars)', 'url': 'https://github.com/joaomdmoura/crewai', 'provider': 'GitHub', 'type': 'framework'}]
        for fw in free_frameworks:
            model = FreeModel(name=f"{fw['provider'].lower()}/{fw['name'].lower().replace(' ', '-')}", provider=fw['provider'], description=fw['description'], url=fw['url'], requires_api_key=False, rate_limit='Framework (no rate limit)')
            frameworks.append(model)
        return frameworks

    def scan_local_models(self) -> List[FreeModel]:
        """Scan for local models that can be run for free"""
        models = []
        local_models = [{'name': 'ollama/llama2', 'description': "Meta's Llama 2 model (local, free)", 'url': 'https://ollama.ai/library/llama2', 'context_window': 4096}, {'name': 'ollama/codellama', 'description': 'Code-specialized Llama model (local, free)', 'url': 'https://ollama.ai/library/codellama', 'context_window': 16384}, {'name': 'ollama/mistral', 'description': 'Mistral AI model (local, free)', 'url': 'https://ollama.ai/library/mistral', 'context_window': 8192}, {'name': 'ollama/phi', 'description': "Microsoft's Phi model (local, free)", 'url': 'https://ollama.ai/library/phi', 'context_window': 2048}, {'name': 'gemini/gemini-2.5-flash-lite', 'description': 'Google Gemini 2.5 Flash Lite (free via CLI)', 'url': 'https://gemini.google.com/', 'context_window': 1048576}, {'name': 'gemini/gemini-2.5-flash', 'description': 'Google Gemini 2.5 Flash (free via CLI)', 'url': 'https://gemini.google.com/', 'context_window': 1048576}, {'name': 'gemini/gemini-1.5-flash', 'description': 'Google Gemini 1.5 Flash (free via CLI)', 'url': 'https://gemini.google.com/', 'context_window': 1048576}, {'name': 'gemini/gemini-1.5-pro', 'description': 'Google Gemini 1.5 Pro (free via CLI)', 'url': 'https://gemini.google.com/', 'context_window': 2097152}]
        for model_data in local_models:
            model = FreeModel(name=model_data['name'], provider='Ollama', description=model_data['description'], url=model_data['url'], requires_api_key=False, rate_limit='Local (no rate limit)', context_window=model_data['context_window'])
            models.append(model)
        return models

    def discover_all_free_models(self) -> List[FreeModel]:
        """Discover free models from all sources"""
        logger.info('Starting comprehensive free model discovery...')
        all_models = []
        scanners = [('Local Models', self.scan_local_models), ('Free API Providers', self.scan_free_api_providers), ('Free Frameworks', self.scan_free_frameworks), ('Hugging Face', self.scan_huggingface_free_models), ('GitHub', self.scan_github_models)]
        for (source_name, scanner_func) in scanners:
            try:
                logger.info(f'Scanning {source_name}...')
                models = scanner_func()
                all_models.extend(models)
                logger.info(f'Found {len(models)} models from {source_name}')
            except Exception as e:
                logger.warning(f'Failed to scan {source_name}: {e}')
        unique_models = self._deduplicate_models(all_models)
        prioritized_models = self._prioritize_discovered_models(unique_models)
        logger.info(f'Discovered {len(prioritized_models)} unique free models total')
        return prioritized_models

    def _is_free_model_repo(self, repo: Dict) -> bool:
        """Check if a GitHub repo contains free models"""
        keywords = ['free', 'open source', 'api', 'model', 'llm', 'language model']
        repo_text = f"{repo.get('description', '')} {repo.get('name', '')}".lower()
        return any((keyword in repo_text for keyword in keywords))

    def _extract_model_from_github_repo(self, repo: Dict) -> FreeModel:
        """Extract model info from GitHub repo"""
        return FreeModel(name=f"github/{repo['name']}", provider='GitHub', description=repo.get('description', 'No description'), url=repo['html_url'], requires_api_key=False)

    def _is_free_huggingface_model(self, model_data: Dict) -> bool:
        """Check if Hugging Face model is free"""
        return True

    def _extract_model_from_huggingface(self, model_data: Dict) -> FreeModel:
        """Extract model info from Hugging Face"""
        model_id = model_data.get('id', '')
        return FreeModel(name=f'huggingface/{model_id}', provider='Hugging Face', description=model_data.get('modelId', 'No description'), url=f'https://huggingface.co/{model_id}', requires_api_key=False)

    def _deduplicate_models(self, models: List[FreeModel]) -> List[FreeModel]:
        """Remove duplicate models"""
        seen = set()
        unique_models = []
        for model in models:
            key = (model.name.lower(), model.provider.lower())
            if key not in seen:
                seen.add(key)
                unique_models.append(model)
        return unique_models

    def _prioritize_discovered_models(self, models: List[FreeModel]) -> List[FreeModel]:
        """Prioritize discovered models based on accessibility and quality"""
        priority_map = {'ollama': 1, 'opencode': 2, 'groq': 3, 'together.ai': 4, 'hugging face': 5, 'github': 6}

        def get_priority(model: FreeModel) -> int:
            provider_lower = model.provider.lower()
            for (provider, priority) in priority_map.items():
                if provider in provider_lower:
                    return priority
            return 999
        return sorted(models, key=get_priority)
if __name__ == '__main__':
    scanner = FreeModelScanner()
    free_models = scanner.discover_all_free_models()
    print('Discovered Free Models:')
    print('=' * 50)
    for model in free_models[:10]:
        print(f'â€¢ {model.name}')
        print(f'  Provider: {model.provider}')
        print(f'  Description: {model.description}')
        print(f'  Rate Limit: {model.rate_limit}')
        print()