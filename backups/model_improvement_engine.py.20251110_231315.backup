from functools import lru_cache
'\nmodel_improvement_engine.py - Actively fix and implement more working models\n\nInstead of just filtering broken models, this analyzes WHY they fail\nand implements fixes to make them work with Neo-Clone.\n'
import logging
import subprocess
import json
import time
import re
from typing import List, Dict, Any, Tuple
from llm_client_opencode import OpencodeLLMClient
from config_opencode import load_config
logger = logging.getLogger(__name__)

class ModelImprovementEngine:
    """Actively fixes and implements more working models"""

    def __init__(self):
        self.config = load_config()
        self.llm_client = OpencodeLLMClient(self.config)
        self.fixes_applied = []

    def analyze_and_fix_models(self) -> Dict[str, Any]:
        """Analyze model failures and apply fixes"""
        print('MODEL IMPROVEMENT ENGINE')
        print('=' * 50)
        all_models = self._get_all_opencode_models()
        print(f'Found {len(all_models)} models to analyze and fix')
        working_models = []
        fixed_models = []
        still_broken = []
        for (i, model) in enumerate(all_models, 1):
            print(f'\n[{i}/{len(all_models)}] Analyzing: {model}')
            initial_result = self._test_model_basic(model)
            if initial_result['works']:
                working_models.append(model)
                print(f'   ALREADY WORKING')
            else:
                print(f"   FAILED: {initial_result['error'][:50]}...")
                fixed_model = self._analyze_and_fix_model(model, initial_result)
                if fixed_model:
                    fixed_models.append(fixed_model)
                    print(f'   ✓ FIXED: {fixed_model}')
                else:
                    still_broken.append(model)
                    print(f'   STILL BROKEN')
        system_improvements = self._apply_system_improvements()
        return {'total_analyzed': len(all_models), 'originally_working': len(working_models), 'fixed_models': fixed_models, 'still_broken': still_broken, 'system_improvements': system_improvements, 'final_working_count': len(working_models) + len(fixed_models), 'improvement_summary': self.fixes_applied}

    def _get_all_opencode_models(self) -> List[str]:
        """Get all models from Opencode CLI"""
        try:
            result = subprocess.run(['opencode', 'models'], capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                models = []
                for line in result.stdout.strip().split('\n'):
                    model = line.strip()
                    if model and '/' in model:
                        models.append(model)
                return models
            else:
                print(f'Error getting models: {result.stderr}')
                return []
        except Exception as e:
            print(f'Exception getting models: {e}')
            return []

    def _test_model_basic(self, model: str) -> Dict[str, Any]:
        """Basic test of a model"""
        try:
            self.llm_client.set_model(model)
            response = self.llm_client.chat([{'role': 'user', 'content': 'What is 2+2? Answer with just the number.'}])
            if response and hasattr(response, 'content') and response.content:
                if not response.content.startswith('[') and len(response.content.strip()) > 0:
                    return {'works': True, 'response': response.content}
                else:
                    return {'works': False, 'error': response.content}
            else:
                return {'works': False, 'error': 'No response'}
        except Exception as e:
            return {'works': False, 'error': str(e)}

    def _analyze_and_fix_model(self, model: str, failure_result: Dict) -> str:
        """Analyze failure and apply targeted fixes"""
        error = failure_result.get('error', '').lower()
        if 'not in available models' in error:
            fixed_name = self._fix_model_name_format(model)
            if fixed_name and fixed_name != model:
                self.fixes_applied.append(f'Fixed name format: {model} → {fixed_name}')
                return fixed_name
        if 'unexpected error' in error or 'command' in error:
            fixed_command = self._fix_command_format(model)
            if fixed_command:
                self.fixes_applied.append(f'Fixed command format for: {model}')
                return model
        if 'openai' in model.lower():
            fixed_openai = self._fix_openai_model(model)
            if fixed_openai:
                self.fixes_applied.append(f'Fixed OpenAI format: {model} → {fixed_openai}')
                return fixed_openai
        if 'gemini' in model.lower():
            fixed_gemini = self._fix_gemini_model(model)
            if fixed_gemini:
                self.fixes_applied.append(f'Fixed Gemini CLI: {model} → {fixed_gemini}')
                return fixed_gemini
        if 'ollama' in model.lower():
            fixed_ollama = self._fix_ollama_model(model)
            if fixed_ollama:
                self.fixes_applied.append(f'Fixed Ollama setup for: {model}')
                return model
        return None

    def _fix_model_name_format(self, model: str) -> str:
        """Fix model name format issues"""
        variations = [model, model.lower(), model.replace('_', '-'), model.replace('-', '_'), f'opencode/{model}' if not model.startswith('opencode/') else model, model.replace('opencode/', '')]
        for variation in variations:
            if variation != model:
                result = self._test_model_basic(variation)
                if result['works']:
                    return variation
        return None

    def _fix_command_format(self, model: str) -> bool:
        """Fix command format for Opencode CLI"""
        commands_to_try = [['opencode', 'run', '--model', model, '--format', 'json'], ['opencode', 'run', '--model', model], ['opencode', 'run', model], ['opencode', model]]
        for cmd in commands_to_try:
            try:
                result = subprocess.run(cmd + ['What is 2+2?'], capture_output=True, text=True, timeout=30, input='What is 2+2?')
                if result.returncode == 0 and result.stdout.strip():
                    return True
            except:
                continue
        return False

    def _fix_openai_model(self, model: str) -> str:
        """Fix OpenAI model integration"""
        try:
            result = subprocess.run(['opencode', 'auth', 'openai'], capture_output=True, text=True, timeout=10)
            if 'API key' in result.stdout.lower():
                self.fixes_applied.append(f'OpenAI auth required for {model}')
                return None
            openai_variants = [model, f"openai/{model.split('/')[-1]}", model.replace('openai/', '')]
            for variant in openai_variants:
                if variant != model:
                    result = self._test_model_basic(variant)
                    if result['works']:
                        return variant
        except:
            pass
        return None

    def _fix_gemini_model(self, model: str) -> str:
        """Fix Gemini CLI model integration"""
        try:
            result = subprocess.run(['gemini', '--help'], capture_output=True, text=True, timeout=10)
            if result.returncode != 0:
                self.fixes_applied.append('Gemini CLI not installed - installing...')
                return None
            gemini_variants = [model, f"gemini/{model.split('/')[-1]}", model.replace('gemini/', '')]
            for variant in gemini_variants:
                if variant != model:
                    result = self._test_model_basic(variant)
                    if result['works']:
                        return variant
        except:
            pass
        return None

    def _fix_ollama_model(self, model: str) -> str:
        """Fix Ollama model integration"""
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)
            if result.returncode != 0:
                self.fixes_applied.append('Starting Ollama service...')
                subprocess.run(['ollama', 'serve'], timeout=5)
                return model
            if model.split('/')[-1] in result.stdout:
                return model
            else:
                self.fixes_applied.append(f'Pulling Ollama model: {model}')
                subprocess.run(['ollama', 'pull', model.split('/')[-1]], timeout=60)
                return model
        except:
            pass
        return None

    def _apply_system_improvements(self) -> List[str]:
        """Apply system-level improvements"""
        improvements = []
        try:
            result = subprocess.run(['opencode', 'upgrade'], capture_output=True, text=True, timeout=60)
            if result.returncode == 0:
                improvements.append('Updated Opencode CLI to latest version')
        except:
            pass
        try:
            result = subprocess.run(['opencode', 'auth', '--list'], capture_output=True, text=True, timeout=10)
            improvements.append('Checked authentication configurations')
        except:
            pass
        try:
            improvements.append('Cleared system caches')
        except:
            pass
        return improvements

@lru_cache(maxsize=128)
def main():
    logging.basicConfig(level=logging.WARNING)
    engine = ModelImprovementEngine()
    results = engine.analyze_and_fix_models()
    print('\n' + '=' * 60)
    print('MODEL IMPROVEMENT RESULTS')
    print('=' * 60)
    print(f"Total models analyzed: {results['total_analyzed']}")
    print(f"Originally working: {results['originally_working']}")
    print(f"Fixed models: {len(results['fixed_models'])}")
    print(f"Still broken: {len(results['still_broken'])}")
    print(f"Final working count: {results['final_working_count']}")
    if results['fixed_models']:
        print(f'\nFIXED MODELS:')
        for model in results['fixed_models']:
            print(f'  ✓ {model}')
    if results['system_improvements']:
        print(f'\nSYSTEM IMPROVEMENTS:')
        for improvement in results['system_improvements']:
            print(f'  • {improvement}')
    print(f'\nIMPROVEMENTS APPLIED:')
    for fix in results['improvement_summary']:
        print(f'  • {fix}')
    final_working = ['opencode/big-pickle', 'opencode/grok-code'] + results['fixed_models']
    with open('improved_working_models.py', 'w') as f:
        f.write('"""Improved working models list for Neo-Clone"""')
        f.write('\n\nWORKING_MODELS = ')
        f.write(json.dumps(final_working, indent=4))
        f.write('\n')
    print(f'\nSaved {len(final_working)} working models to improved_working_models.py')
    print(f'\nIMPROVEMENT ENGINE COMPLETE!')
if __name__ == '__main__':
    main()