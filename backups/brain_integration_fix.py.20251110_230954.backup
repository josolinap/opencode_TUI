from functools import lru_cache
'\nNeo-Clone Brain Integration Fix\nResolves technical issues with brain_opencode.py integration\n'
import sys
import os
import logging
import time
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from pathlib import Path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Message:
    """Simple message structure"""
    role: str
    content: str
    timestamp: Optional[float] = None

    def __post_init__(self):
        if self.timestamp is None:
            import time
            self.timestamp = time.time()

class ConversationHistory:
    """Simple conversation history"""

    def __init__(self, max_messages: int=20):
        self.max_messages = max_messages
        self._messages: List[Message] = []
        import time
        self.session_start = time.time()

    def add(self, role: str, content: str):
        self._messages.append(Message(role=role, content=content))
        if len(self._messages) > self.max_messages:
            self._messages = self._messages[-self.max_messages:]

    def to_list(self) -> List[Dict[str, str]]:
        return [{'role': m.role, 'content': m.content} for m in self._messages]

    def clear(self):
        self._messages = []
        import time
        self.session_start = time.time()

class MockSkill:
    """Mock skill for testing"""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.example_usage = f'Example usage of {name}'

    def execute(self, params: Dict[str, Any]) -> str:
        return f'Mock skill {self.name} executed with params: {params}'

class MockSkillRegistry:
    """Mock skill registry for testing"""

    def __init__(self):
        self.skills = {'code_generation': MockSkill('Code Generation', 'Generates code snippets'), 'text_analysis': MockSkill('Text Analysis', 'Analyzes text content'), 'data_inspector': MockSkill('Data Inspector', 'Inspects data files'), 'file_manager': MockSkill('File Manager', 'Manages files'), 'web_search': MockSkill('Web Search', 'Searches the web'), 'minimax_agent': MockSkill('MiniMax Agent', 'Advanced reasoning agent')}

    def get(self, name: str) -> MockSkill:
        return self.skills.get(name, MockSkill('Unknown', 'Unknown skill'))

class MockConfig:
    """Mock configuration for testing"""

    def __init__(self):
        self.provider = 'mock'
        self.model_name = 'mock-model'
        self.opencode_model = None
        self.api_endpoint = 'http://localhost:11434'
        self.api_key = None
        self.max_tokens = 1024
        self.temperature = 0.7
        self.system_prompt = None

class MockLLMClient:
    """Mock LLM client for testing"""

    def __init__(self, config):
        self.config = config
        self.current_model = f'{config.provider}/{config.model_name}'

    def chat(self, messages: List[Dict[str, str]]) -> Any:

        class MockResponse:

            def __init__(self):
                self.content = 'This is a mock response from the LLM client.'
                self.model = 'mock-model'
                self.provider = 'mock'
                self.usage = {'prompt_tokens': 10, 'completion_tokens': 20}
        return MockResponse()

    def set_model(self, model: str):
        self.current_model = model

    def get_current_model(self) -> str:
        return self.current_model

    def get_available_models(self) -> List[str]:
        return ['mock/model1', 'mock/model2', 'mock/model3']

class FixedNeoCloneBrain:
    """Fixed Neo-Clone Brain with proper error handling"""

    def __init__(self):
        self.config = MockConfig()
        self.skills = MockSkillRegistry()
        self.llm = MockLLMClient(self.config)
        self.history = ConversationHistory()
        self.model_switch_count = 0
        self._try_load_real_components()
        logger.info('Neo-Clone Brain initialized successfully')

    @lru_cache(maxsize=128)
    def _try_load_real_components(self):
        """Try to load real components with proper error handling"""
        try:
            try:
                from config_opencode import Config, load_config, get_current_opencode_model
                self.config = load_config()
                logger.info('Loaded real config_opencode')
            except ImportError as e:
                logger.warning(f'Could not import config_opencode: {e}')
            except Exception as e:
                logger.warning(f'Error loading config: {e}')
            try:
                from skills import SkillRegistry
                self.skills = SkillRegistry()
                logger.info('Loaded real skills registry')
            except ImportError as e:
                logger.warning(f'Could not import skills: {e}')
            except Exception as e:
                logger.warning(f'Error loading skills: {e}')
            try:
                from llm_client_opencode import LLMClient
                self.llm = LLMClient(self.config)
                logger.info('Loaded real LLM client')
            except ImportError as e:
                logger.warning(f'Could not import llm_client_opencode: {e}')
            except Exception as e:
                logger.warning(f'Error loading LLM client: {e}')
        except Exception as e:
            logger.error(f'Unexpected error loading components: {e}')

    def parse_intent(self, text: str) -> Dict[str, str]:
        """Parse user intent with robust error handling"""
        try:
            lowered = text.lower().strip()
            if lowered.startswith('/model') or 'switch model' in lowered or 'change model' in lowered:
                return {'intent': 'model_switch', 'action': 'switch_model'}
            skill_keywords = {'ml_training': ['train', 'model', 'simulate', 'recommend', 'ml'], 'text_analysis': ['sentiment', 'analyze', 'moderate', 'toxic', 'text'], 'data_inspector': ['csv', 'json', 'data', 'summary', 'stats', 'inspect'], 'code_generation': ['code', 'python', 'generate', 'snippet', 'explain', 'programming'], 'file_manager': ['file', 'manage', 'organize', 'directory'], 'web_search': ['search', 'web', 'internet', 'find'], 'minimax_agent': ['minimax', 'reasoning', 'analyze', 'generate', 'think']}
            for (skill, keywords) in skill_keywords.items():
                if any((word in lowered for word in keywords)):
                    return {'intent': 'skill', 'skill': skill}
            return {'intent': 'chat'}
        except Exception as e:
            logger.error(f'Error parsing intent: {e}')
            return {'intent': 'chat'}

    def route_to_skill(self, skill_name: str, text: str, context: Optional[Dict]=None) -> Dict:
        """Route to skill with error handling"""
        try:
            skill = self.skills.get(skill_name)
            params = {'text': text}
            if context:
                params.update(context)
            result = skill.execute(params)
            return {'chosen_skill': skill_name, 'meta': {'description': skill.description, 'example': skill.example_usage, 'parameters': getattr(skill, 'parameters', {})}, 'output': result, 'reasoning': f"Chose skill '{skill_name}' due to detected keywords and context analysis."}
        except Exception as e:
            logger.error(f'Skill routing failed for {skill_name}: {e}')
            return {'error': f'Skill routing failed: {e}'}

    def handle_model_switch(self, text: str) -> str:
        """Handle model switching with error handling"""
        try:
            if text.startswith('/model'):
                parts = text.split(None, 1)
                if len(parts) > 1:
                    new_model = parts[1].strip()
                    return self.switch_model(new_model)
                else:
                    return self.show_available_models()
            else:
                return 'Model switching format: /model <provider/model>'
        except Exception as e:
            logger.error(f'Error handling model switch: {e}')
            return f'Error switching model: {e}'

    def switch_model(self, model: str) -> str:
        """Switch model with error handling"""
        try:
            self.llm.set_model(model)
            self.model_switch_count += 1
            if hasattr(self.config, 'opencode_model'):
                self.config.opencode_model = model
            logger.info(f'Model switched to: {model}')
            return f'Model switched to: {model}'
        except Exception as e:
            error_msg = f'Failed to switch model: {str(e)}'
            logger.error(error_msg)
            return error_msg

    def show_available_models(self) -> str:
        """Show available models with error handling"""
        try:
            models = self.llm.get_available_models()
            current = self.llm.get_current_model()
            if not models:
                return 'No models available. Please configure your LLM provider.'
            result = [f'Available Models (current: {current}):\n']
            for model in models[:10]:
                marker = '-> ' if model == current else '   '
                result.append(f'{marker}{model}')
            if len(models) > 10:
                result.append(f'... and {len(models) - 10} more')
            result.append(f"\nUse '/model {(models[0] if models else 'provider/model')}' to switch")
            return '\n'.join(result)
        except Exception as e:
            logger.error(f'Error showing available models: {e}')
            return f'Error getting available models: {e}'

    def send_message(self, text: str, context: Optional[Dict]=None) -> str:
        """Send message with comprehensive error handling"""
        try:
            self.history.add('user', text)
            intent = self.parse_intent(text)
            if intent.get('intent') == 'model_switch':
                response = self.handle_model_switch(text)
                self.history.add('assistant', response)
                return response
            if intent.get('intent') == 'skill' and intent.get('skill'):
                skill_name = intent['skill']
                result = self.route_to_skill(skill_name, text, context)
                self.history.add('assistant', f'[Skill:{skill_name}] {result}')
                if 'error' in result:
                    return f"[Error] {result['error']}"
                return f"[Neo Reasoning] {result['reasoning']}\n\n[Skill Output]\n{result['output']}"
            try:
                response = self.llm.chat(self.history.to_list())
                self.history.add('assistant', response.content)
                model_info = f' ({response.provider}/{response.model})' if hasattr(response, 'provider') and response.provider != 'error' else ''
                return response.content + model_info
            except Exception as e:
                error_msg = f'[Neo Error] LLM request failed: {str(e)}'
                logger.error(error_msg)
                return error_msg
        except Exception as e:
            error_msg = f'[Neo Error] Message processing failed: {str(e)}'
            logger.error(error_msg)
            return error_msg

    def get_status(self) -> Dict[str, Any]:
        """Get brain status with error handling"""
        try:
            current_model = self.llm.get_current_model()
            status = {'current_model': current_model, 'provider': getattr(self.config, 'provider', 'unknown'), 'model_name': getattr(self.config, 'model_name', 'unknown'), 'opencode_model': getattr(self.config, 'opencode_model', None), 'is_opencode_available': getattr(self.config, 'opencode_model', None) is not None, 'model_switches': self.model_switch_count, 'conversation_stats': {'message_count': len(self.history._messages), 'session_duration': getattr(self.history, 'session_start', 0) and time.time() - self.history.session_start or 0}, 'available_skills': list(self.skills.skills.keys()) if hasattr(self.skills, 'skills') else [], 'config_source': 'opencode' if getattr(self.config, 'opencode_model', None) else 'local/mock', 'status': 'operational'}
            return status
        except Exception as e:
            logger.error(f'Error getting status: {e}')
            return {'status': 'error', 'error': str(e), 'current_model': 'unknown', 'provider': 'unknown'}

def test_brain_integration():
    """Test the fixed brain integration"""
    print('Testing Neo-Clone Brain Integration Fix')
    print('=' * 50)
    brain = FixedNeoCloneBrain()
    print('\n1. Testing basic chat:')
    response = brain.send_message('Hello, how are you?')
    print(f'Response: {response}')
    print('\n2. Testing skill routing:')
    response = brain.send_message('Generate some Python code')
    print(f'Response: {response}')
    print('\n3. Testing model switching:')
    response = brain.send_message('/model')
    print(f'Response: {response}')
    print('\n4. Testing model switching to specific model:')
    response = brain.send_message('/model test/model')
    print(f'Response: {response}')
    print('\n5. Getting brain status:')
    status = brain.get_status()
    print(f'Status: {status}')
    print('\n[SUCCESS] Brain integration test completed successfully!')
if __name__ == '__main__':
    test_brain_integration()