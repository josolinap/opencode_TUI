from functools import lru_cache
'\nNeo-Clone Advanced Chat System\nContext-aware, intelligent conversation management with multi-model support\n'
import asyncio
import json
import time
import re
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque
import hashlib

class MessageRole(Enum):
    """Message role types"""
    USER = 'user'
    ASSISTANT = 'assistant'
    SYSTEM = 'system'
    TOOL = 'tool'
    CRITIC = 'critic'

class ConversationType(Enum):
    """Conversation types"""
    GENERAL = 'general'
    CODING = 'coding'
    ANALYSIS = 'analysis'
    DEBUGGING = 'debugging'
    LEARNING = 'learning'
    WORKFLOW = 'workflow'

@dataclass
class ContextItem:
    """Context item for conversation awareness"""
    key: str
    value: Any
    timestamp: datetime
    importance: float = 1.0
    ttl: Optional[float] = None
    category: str = 'general'

    def is_expired(self) -> bool:
        """Check if context item has expired"""
        if self.ttl is None:
            return False
        return (datetime.now() - self.timestamp).total_seconds() > self.ttl

@dataclass
class ChatMessage:
    """Enhanced chat message with context"""
    id: str
    role: MessageRole
    content: str
    timestamp: datetime
    context_items: List[ContextItem] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    skill_used: Optional[str] = None
    response_time: Optional[float] = None
    tokens_used: Optional[int] = None
    model_used: Optional[str] = None
    conversation_id: Optional[str] = None
    parent_id: Optional[str] = None
    children_ids: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        return {**asdict(self), 'role': self.role.value, 'timestamp': self.timestamp.isoformat(), 'context_items': [asdict(item) for item in self.context_items]}

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ChatMessage':
        """Create from dictionary"""
        data['role'] = MessageRole(data['role'])
        data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        data['context_items'] = [ContextItem(**item) for item in data.get('context_items', [])]
        return cls(**data)

@dataclass
class Conversation:
    """Conversation with context management"""
    id: str
    title: str
    type: ConversationType
    created_at: datetime
    updated_at: datetime
    messages: List[ChatMessage] = field(default_factory=list)
    context: Dict[str, ContextItem] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    is_active: bool = True

    def add_message(self, message: ChatMessage):
        """Add message to conversation"""
        message.conversation_id = self.id
        self.messages.append(message)
        self.updated_at = datetime.now()
        for context_item in message.context_items:
            self.context[context_item.key] = context_item

    def get_context_summary(self, max_items: int=10) -> Dict[str, Any]:
        """Get summary of current context"""
        active_context = {key: item for (key, item) in self.context.items() if not item.is_expired()}
        sorted_items = sorted(active_context.values(), key=lambda x: (x.importance, x.timestamp), reverse=True)
        return {'total_items': len(active_context), 'top_items': [{'key': item.key, 'value': str(item.value)[:100], 'importance': item.importance, 'category': item.category} for item in sorted_items[:max_items]]}

    def get_recent_messages(self, count: int=10) -> List[ChatMessage]:
        """Get recent messages"""
        return self.messages[-count:] if self.messages else []

class ContextManager:
    """Manages conversation context with intelligent pruning"""

    def __init__(self, max_context_items: int=100, context_ttl: float=3600):
        self.max_context_items = max_context_items
        self.context_ttl = context_ttl
        self.context: Dict[str, ContextItem] = {}
        self.importance_weights = {'file_path': 0.9, 'current_task': 0.8, 'error_message': 0.7, 'user_preference': 0.6, 'code_snippet': 0.5, 'general_info': 0.3}

    def add_context(self, key: str, value: Any, category: str='general', importance: Optional[float]=None, ttl: Optional[float]=None):
        """Add context item"""
        if importance is None:
            importance = self.importance_weights.get(category, 0.5)
        context_item = ContextItem(key=key, value=value, timestamp=datetime.now(), importance=importance, ttl=ttl or self.context_ttl, category=category)
        self.context[key] = context_item
        self._prune_context()

    def get_context(self, key: str) -> Optional[ContextItem]:
        """Get specific context item"""
        item = self.context.get(key)
        if item and (not item.is_expired()):
            return item
        return None

    def get_relevant_context(self, query: str, max_items: int=20) -> List[ContextItem]:
        """Get context relevant to query"""
        active_context = [item for item in self.context.values() if not item.is_expired()]
        query_words = set(query.lower().split())
        scored_items = []
        for item in active_context:
            item_text = str(item.value).lower()
            item_words = set(item_text.split())
            common_words = query_words.intersection(item_words)
            relevance_score = len(common_words) / max(len(query_words), 1)
            final_score = relevance_score * 0.6 + item.importance * 0.4
            scored_items.append((final_score, item))
        scored_items.sort(key=lambda x: x[0], reverse=True)
        return [item for (_, item) in scored_items[:max_items]]

    def _prune_context(self):
        """Prune old/less important context items"""
        if len(self.context) <= self.max_context_items:
            return
        expired_keys = [key for (key, item) in self.context.items() if item.is_expired()]
        for key in expired_keys:
            del self.context[key]
        if len(self.context) > self.max_context_items:
            scored_items = [(item.importance * (1 - (datetime.now() - item.timestamp).total_seconds() / self.context_ttl), key) for (key, item) in self.context.items()]
            scored_items.sort(key=lambda x: x[0])
            items_to_remove = len(self.context) - self.max_context_items
            for (_, key) in scored_items[:items_to_remove]:
                del self.context[key]

class ConversationManager:
    """Manages multiple conversations with intelligent routing"""

    def __init__(self, max_conversations: int=50):
        self.conversations: Dict[str, Conversation] = {}
        self.max_conversations = max_conversations
        self.active_conversation_id: Optional[str] = None
        self.context_manager = ContextManager()

    def create_conversation(self, title: str, conv_type: ConversationType=ConversationType.GENERAL) -> str:
        """Create new conversation"""
        conv_id = hashlib.md5(f'{title}{datetime.now().isoformat()}'.encode()).hexdigest()[:8]
        conversation = Conversation(id=conv_id, title=title, type=conv_type, created_at=datetime.now(), updated_at=datetime.now())
        self.conversations[conv_id] = conversation
        self.active_conversation_id = conv_id
        self._prune_conversations()
        return conv_id

    def get_active_conversation(self) -> Optional[Conversation]:
        """Get currently active conversation"""
        if self.active_conversation_id:
            return self.conversations.get(self.active_conversation_id)
        return None

    def switch_conversation(self, conv_id: str) -> bool:
        """Switch to different conversation"""
        if conv_id in self.conversations:
            self.active_conversation_id = conv_id
            return True
        return False

    def add_message(self, role: MessageRole, content: str, context_items: Optional[List[ContextItem]]=None, metadata: Optional[Dict[str, Any]]=None) -> str:
        """Add message to active conversation"""
        active_conv = self.get_active_conversation()
        if not active_conv:
            self.create_conversation('New Conversation')
            active_conv = self.get_active_conversation()
        message_id = hashlib.md5(f'{content}{datetime.now().isoformat()}'.encode()).hexdigest()[:8]
        message = ChatMessage(id=message_id, role=role, content=content, timestamp=datetime.now(), context_items=context_items or [], metadata=metadata or {})
        active_conv.add_message(message)
        for context_item in message.context_items:
            self.context_manager.add_context(context_item.key, context_item.value, context_item.category, context_item.importance, context_item.ttl)
        return message_id

    def get_conversation_history(self, conv_id: Optional[str]=None, limit: int=50) -> List[ChatMessage]:
        """Get conversation history"""
        conv_id = conv_id or self.active_conversation_id
        if conv_id and conv_id in self.conversations:
            return self.conversations[conv_id].get_recent_messages(limit)
        return []

    def search_conversations(self, query: str) -> List[Conversation]:
        """Search conversations by content"""
        query_words = set(query.lower().split())
        results = []
        for conv in self.conversations.values():
            for message in conv.messages:
                message_words = set(message.content.lower().split())
                if query_words.intersection(message_words):
                    results.append(conv)
                    break
        results.sort(key=lambda x: x.updated_at, reverse=True)
        return results

    def _prune_conversations(self):
        """Prune old conversations"""
        if len(self.conversations) <= self.max_conversations:
            return
        sorted_convs = sorted(self.conversations.items(), key=lambda x: x[1].updated_at)
        items_to_remove = len(self.conversations) - self.max_conversations
        for (conv_id, _) in sorted_convs[:items_to_remove]:
            if conv_id != self.active_conversation_id:
                del self.conversations[conv_id]

class IntelligentResponseGenerator:
    """Generates intelligent responses with context awareness"""

    def __init__(self, skill_manager):
        self.skill_manager = skill_manager
        self.response_patterns = {'greeting': '^(hi|hello|hey|good morning|good afternoon|good evening)', 'question': '.*\\?', 'code_request': '(write|create|generate|code|function|class)', 'help_request': '(help|assist|support|how to)', 'error_report': '(error|issue|problem|bug|not working)', 'file_operation': '(file|folder|directory|save|open|read)', 'analysis_request': '(analyze|analysis|review|examine)', 'debug_request': '(debug|fix|troubleshoot|resolve)'}

    async def generate_response(self, user_input: str, conversation: Conversation, conversation_manager: ConversationManager) -> Tuple[str, Optional[str]]:
        """Generate intelligent response based on input and context"""
        relevant_context = conversation_manager.context_manager.get_relevant_context(user_input)
        input_type = self._analyze_input_type(user_input)
        if input_type == 'greeting':
            response = self._generate_greeting_response(conversation)
            skill_used = None
        elif input_type == 'code_request':
            (response, skill_used) = await self._handle_code_request(user_input, relevant_context)
        elif input_type == 'help_request':
            (response, skill_used) = await self._handle_help_request(user_input, relevant_context)
        elif input_type == 'error_report':
            (response, skill_used) = await self._handle_error_report(user_input, relevant_context)
        elif input_type == 'file_operation':
            (response, skill_used) = await self._handle_file_operation(user_input, relevant_context)
        elif input_type == 'analysis_request':
            (response, skill_used) = await self._handle_analysis_request(user_input, relevant_context)
        elif input_type == 'debug_request':
            (response, skill_used) = await self._handle_debug_request(user_input, relevant_context)
        else:
            (response, skill_used) = await self._handle_general_query(user_input, relevant_context)
        return (response, skill_used)

    def _analyze_input_type(self, user_input: str) -> str:
        """Analyze the type of user input"""
        user_input_lower = user_input.lower()
        for (pattern_type, pattern) in self.response_patterns.items():
            if re.match(pattern, user_input_lower):
                return pattern_type
        return 'general'

    def _generate_greeting_response(self, conversation: Conversation) -> str:
        """Generate greeting response"""
        greetings = ["Hello! I'm Neo-Clone, your advanced AI assistant. How can I help you today?", "Hi there! I'm ready to assist you with coding, analysis, debugging, and more!", 'Greetings! I have access to 19+ skills and can help with various tasks. What would you like to work on?']
        if len(conversation.messages) > 5:
            return "Welcome back! I'm ready to continue where we left off. What's next?"
        return greetings[hash(str(conversation.id)) % len(greetings)]

    async def _handle_code_request(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle code generation requests"""
        try:
            code_requirements = self._extract_code_requirements(user_input, context)
            result = await self.skill_manager.execute_skill('code_generation', 'generate_code', code_requirements)
            return (f"I've generated the code you requested:\n\n```python\n{result}\n```", 'code_generation.generate_code')
        except Exception as e:
            return (f'I encountered an error generating code: {str(e)}', None)

    async def _handle_help_request(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle help requests"""
        skills = self.skill_manager.list_skills()
        help_text = 'I can help you with the following:\n\n'
        categories = defaultdict(list)
        for skill in skills:
            if skill.loaded:
                category = self._categorize_skill(skill.name)
                categories[category].append(skill)
        for (category, skill_list) in categories.items():
            help_text += f'**{category.title()}**:\n'
            for skill in skill_list[:3]:
                help_text += f'â€¢ {skill.name}: {skill.description}\n'
            help_text += '\n'
        help_text += 'You can also ask me specific questions or give me tasks directly!'
        return (help_text, None)

    async def _handle_error_report(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle error reports"""
        error_info = self._extract_error_info(user_input, context)
        try:
            result = await self.skill_manager.execute_skill('autonomous_reasoning_skill', 'analyze_error', error_info)
            return (f"I've analyzed the error:\n\n{result}", 'autonomous_reasoning_skill.analyze_error')
        except Exception as e:
            return (f'I can help with that error. Could you provide more details about the issue?', None)

    async def _handle_file_operation(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle file operations"""
        try:
            result = await self.skill_manager.execute_skill('file_manager', 'handle_file_request', user_input)
            return (f'File operation completed:\n\n{result}', 'file_manager.handle_file_request')
        except Exception as e:
            return (f'I can help with file operations. What would you like to do with files?', None)

    async def _handle_analysis_request(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle analysis requests"""
        try:
            result = await self.skill_manager.execute_skill('analytics_skill', 'analyze_data', user_input)
            return (f'Analysis results:\n\n{result}', 'analytics_skill.analyze_data')
        except Exception as e:
            return (f'I can help with analysis. What data or information would you like me to analyze?', None)

    async def _handle_debug_request(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle debugging requests"""
        try:
            result = await self.skill_manager.execute_skill('autonomous_reasoning_skill', 'debug_issue', user_input)
            return (f'Debugging analysis:\n\n{result}', 'autonomous_reasoning_skill.debug_issue')
        except Exception as e:
            return (f'I can help with debugging. Could you provide the code or issue details?', None)

    async def _handle_general_query(self, user_input: str, context: List[ContextItem]) -> Tuple[str, str]:
        """Handle general queries"""
        relevant_skill = self._find_relevant_skill(user_input)
        if relevant_skill:
            try:
                result = await self.skill_manager.execute_skill(relevant_skill.name, 'process_query', user_input)
                return (f"Here's what I found:\n\n{result}", f'{relevant_skill.name}.process_query')
            except Exception as e:
                pass
        return (self._generate_intelligent_fallback(user_input, context), None)

    def _extract_code_requirements(self, user_input: str, context: List[ContextItem]) -> str:
        """Extract code requirements from input and context"""
        requirements = user_input
        context_info = [item.value for item in context if item.category == 'code_snippet']
        if context_info:
            requirements += f"\n\nContext: {(context_info[-1] if context_info else '')}"
        return requirements

    def _extract_error_info(self, user_input: str, context: List[ContextItem]) -> Dict[str, Any]:
        """Extract error information from input and context"""
        return {'error_message': user_input, 'context': [item.value for item in context if item.category == 'error_message'], 'timestamp': datetime.now().isoformat()}

    @lru_cache(maxsize=128)
    def _categorize_skill(self, skill_name: str) -> str:
        """Categorize skill by name"""
        if 'code' in skill_name or 'ml' in skill_name:
            return 'Development'
        elif 'file' in skill_name or 'data' in skill_name:
            return 'Data Management'
        elif 'web' in skill_name or 'search' in skill_name:
            return 'Information'
        elif 'analytics' in skill_name or 'reasoning' in skill_name:
            return 'Analysis'
        else:
            return 'General'

    def _find_relevant_skill(self, user_input: str) -> Optional[Any]:
        """Find relevant skill based on keywords"""
        skills = self.skill_manager.list_skills()
        user_input_lower = user_input.lower()
        skill_keywords = {'web_search': ['search', 'find', 'look up', 'web', 'internet'], 'text_analysis': ['analyze', 'text', 'sentiment', 'extract'], 'file_manager': ['file', 'folder', 'directory', 'save', 'open'], 'analytics_skill': ['analytics', 'metrics', 'statistics', 'data'], 'ml_training': ['machine learning', 'ml', 'train', 'model'], 'automated_workflows': ['workflow', 'automate', 'process', 'pipeline']}
        for (skill_name, keywords) in skill_keywords.items():
            if any((keyword in user_input_lower for keyword in keywords)):
                for skill in skills:
                    if skill.name == skill_name and skill.loaded:
                        return skill
        return None

    def _generate_intelligent_fallback(self, user_input: str, context: List[ContextItem]) -> str:
        """Generate intelligent fallback response"""
        if context:
            context_summary = f"I see we've been discussing: {context[0].key}. "
        else:
            context_summary = ''
        responses = [f"{context_summary}I understand you're asking about '{user_input}'. I can help with this using my various skills. Could you provide more specific details about what you'd like me to do?", f"{context_summary}That's an interesting question! I have access to 19+ skills including code generation, file management, web search, and analytics. How would you like me to approach this?", f"{context_summary}I'd be happy to help with '{user_input}'. I can assist with coding, analysis, debugging, file operations, and more. What specific aspect would you like me to focus on?"]
        return responses[hash(user_input) % len(responses)]

async def main():
    """Test the advanced chat system"""
    from neo_clone_tui_enhanced import SkillManager
    skill_manager = SkillManager()
    conversation_manager = ConversationManager()
    response_generator = IntelligentResponseGenerator(skill_manager)
    conv_id = conversation_manager.create_conversation('Test Conversation', ConversationType.GENERAL)
    conversation = conversation_manager.get_active_conversation()
    print('Neo-Clone Advanced Chat System Test')
    print('=' * 50)
    test_inputs = ['Hello, how are you?', 'Can you help me write a Python function to calculate factorial?', "I'm getting an error in my code", 'Can you analyze this data for me?', 'Help me with file operations']
    for (i, user_input) in enumerate(test_inputs):
        print(f'\n--- Test {i + 1} ---')
        print(f'User: {user_input}')
        conversation_manager.add_message(MessageRole.USER, user_input)
        (response, skill_used) = await response_generator.generate_response(user_input, conversation, conversation_manager)
        print(f'Assistant: {response[:200]}...')
        if skill_used:
            print(f'Skill used: {skill_used}')
        conversation_manager.add_message(MessageRole.ASSISTANT, response, metadata={'skill_used': skill_used})
    print(f'\n--- Conversation Summary ---')
    print(f'Total messages: {len(conversation.messages)}')
    print(f'Context items: {len(conversation.context)}')
    context_summary = conversation.get_context_summary()
    print(f"Active context: {context_summary['total_items']} items")
if __name__ == '__main__':
    asyncio.run(main())