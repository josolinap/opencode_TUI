from functools import lru_cache
'\nautonomous_code_review.py - Autonomous Code Review and Analysis Skill\n\nProvides:\n- Automated code quality assessment\n- Security vulnerability detection\n- Performance optimization suggestions\n- Best practices compliance checking\n- Code complexity analysis\n- Automated refactoring recommendations\n'
import ast
import re
import json
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import logging
from collections import defaultdict, Counter
import inspect
from datetime import datetime
from skills import BaseSkill
logger = logging.getLogger(__name__)

class AutonomousCodeReviewSkill(BaseSkill):
    """Autonomous code review and analysis system"""

    def __init__(self):
        self.code_patterns = self._load_code_patterns()
        self.security_rules = self._load_security_rules()
        self.performance_indicators = self._load_performance_indicators()

    @property
    def name(self) -> str:
        return 'autonomous_code_review'

    @property
    def description(self) -> str:
        return 'Autonomous code review with quality assessment, security analysis, and improvement suggestions'

    @property
    def example_usage(self) -> str:
        return 'Review this Python file for quality, security, and performance issues'

    @lru_cache(maxsize=128)
    def execute(self, params: Dict[str, Any]) -> Dict[str, Any]:
        code = params.get('code', '')
        file_path = params.get('file_path', '')
        language = params.get('language', 'python')
        review_depth = params.get('review_depth', 'comprehensive')
        if not code and (not file_path):
            return {'error': 'No code or file path provided for review'}
        if file_path and (not code):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    code = f.read()
                language = self._detect_language(file_path)
            except Exception as e:
                return {'error': f'Failed to read file: {str(e)}'}
        if not code.strip():
            return {'error': 'Empty code provided for review'}
        try:
            review_result = {'language': language, 'code_length': len(code), 'lines_of_code': len(code.split('\n')), 'review_depth': review_depth, 'timestamp': str(datetime.now())}
            if review_depth in ['detailed', 'comprehensive']:
                review_result.update({'quality_score': self._assess_code_quality(code, language), 'security_analysis': self._analyze_security(code, language), 'performance_analysis': self._analyze_performance(code, language), 'maintainability_score': self._assess_maintainability(code, language)})
            if review_depth == 'comprehensive':
                review_result.update({'complexity_analysis': self._analyze_complexity(code, language), 'best_practices_check': self._check_best_practices(code, language), 'refactoring_suggestions': self._generate_refactoring_suggestions(code, language), 'test_coverage_suggestions': self._suggest_test_coverage(code, language)})
            review_result['basic_analysis'] = self._basic_code_analysis(code, language)
            return review_result
        except Exception as e:
            logger.error(f'Code review failed: {e}')
            return {'error': f'Code review failed: {str(e)}', 'partial_results': {'language': language, 'code_length': len(code)}}

    def _detect_language(self, file_path: str) -> str:
        """Detect programming language from file extension"""
        ext = Path(file_path).suffix.lower()
        language_map = {'.py': 'python', '.js': 'javascript', '.ts': 'typescript', '.java': 'java', '.cpp': 'cpp', '.c': 'c', '.go': 'go', '.rs': 'rust', '.php': 'php', '.rb': 'ruby'}
        return language_map.get(ext, 'unknown')

    def _basic_code_analysis(self, code: str, language: str) -> Dict[str, Any]:
        """Perform basic code analysis"""
        lines = code.split('\n')
        analysis = {'total_lines': len(lines), 'empty_lines': sum((1 for line in lines if not line.strip())), 'comment_lines': sum((1 for line in lines if line.strip().startswith('#'))) if language == 'python' else 0, 'code_lines': len([line for line in lines if line.strip() and (not line.strip().startswith('#'))])}
        if language == 'python':
            analysis.update({'functions': len(re.findall('\\bdef\\s+\\w+', code)), 'classes': len(re.findall('\\bclass\\s+\\w+', code)), 'imports': len(re.findall('\\b(import|from)\\s+', code))})
        return analysis

    def _assess_code_quality(self, code: str, language: str) -> Dict[str, Any]:
        """Assess overall code quality"""
        score = 100
        issues = []
        if language == 'python':
            try:
                tree = ast.parse(code)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        if len(node.body) > 50:
                            score -= 10
                            issues.append(f"Function '{node.name}' is too long ({len(node.body)} lines)")
                        if len(node.args.args) > 5:
                            score -= 5
                            issues.append(f"Function '{node.name}' has too many parameters ({len(node.args.args)})")
                bare_excepts = [node for node in ast.walk(tree) if isinstance(node, ast.ExceptHandler) and (not node.type)]
                if bare_excepts:
                    score -= 15
                    issues.append(f"Found {len(bare_excepts)} bare 'except:' clauses")
            except SyntaxError:
                score -= 50
                issues.append('Code contains syntax errors')
        lines = code.split('\n')
        line_counts = Counter(lines)
        duplicates = [line for (line, count) in line_counts.items() if count > 1 and line.strip()]
        if duplicates:
            score -= min(len(duplicates) * 5, 20)
            issues.append(f'Found {len(duplicates)} duplicate lines')
        return {'score': max(0, score), 'grade': self._score_to_grade(score), 'issues': issues, 'recommendations': self._generate_quality_recommendations(issues)}

    def _analyze_security(self, code: str, language: str) -> Dict[str, Any]:
        """Analyze code for security vulnerabilities"""
        vulnerabilities = []
        risk_level = 'low'
        if language == 'python':
            dangerous_patterns = [('eval\\s*\\(', 'HIGH', 'Use of eval() - potential code injection'), ('exec\\s*\\(', 'HIGH', 'Use of exec() - potential code injection'), ('input\\s*\\(', 'MEDIUM', 'Use of input() - potential security risk'), ('subprocess\\..*shell.*=.*True', 'HIGH', 'Shell execution with shell=True'), ('os\\.system\\s*\\(', 'MEDIUM', 'Use of os.system()'), ('pickle\\.loads?\\s*\\(', 'MEDIUM', 'Use of pickle - potential deserialization attacks')]
            for (pattern, level, description) in dangerous_patterns:
                matches = re.findall(pattern, code)
                if matches:
                    vulnerabilities.append({'type': 'security_vulnerability', 'severity': level, 'description': description, 'occurrences': len(matches), 'line_numbers': self._find_line_numbers(code, pattern)})
                    if level == 'HIGH':
                        risk_level = 'high'
                    elif level == 'MEDIUM' and risk_level == 'low':
                        risk_level = 'medium'
        secret_patterns = ['password\\s*=\\s*["\\\'][^"\\\']+["\\\']', 'api_key\\s*=\\s*["\\\'][^"\\\']+["\\\']', 'secret\\s*=\\s*["\\\'][^"\\\']+["\\\']', 'token\\s*=\\s*["\\\'][^"\\\']+["\\\']']
        for pattern in secret_patterns:
            if re.search(pattern, code, re.IGNORECASE):
                vulnerabilities.append({'type': 'hardcoded_secret', 'severity': 'HIGH', 'description': 'Potential hardcoded secret detected', 'recommendation': 'Use environment variables or secure credential storage'})
                risk_level = 'high'
        return {'risk_level': risk_level, 'vulnerabilities_found': len(vulnerabilities), 'vulnerabilities': vulnerabilities, 'security_score': 100 - len(vulnerabilities) * 20}

    def _analyze_performance(self, code: str, language: str) -> Dict[str, Any]:
        """Analyze code for performance issues"""
        issues = []
        suggestions = []
        if language == 'python':
            inefficient_patterns = [('for.*in.*range.*len\\s*\\(', 'Use enumerate() instead of range(len())'), ('\\.append\\s*\\([^)]*\\)\\s*$', 'Consider using list comprehensions for multiple appends'), ('\\+=\\s*string', 'String concatenation in loop - use join() instead'), ('print\\s*\\([^)]*\\)', 'Remove debug print statements in production')]
            for (pattern, suggestion) in inefficient_patterns:
                if re.search(pattern, code):
                    issues.append(suggestion)
                    suggestions.append(f"Replace pattern matching '{pattern}' with more efficient alternatives")
            if 'list(' in code and 'range(' in code and ('10000' in code):
                issues.append('Large list creation detected')
                suggestions.append('Consider using generators for large datasets')
        return {'performance_issues': len(issues), 'issues': issues, 'optimization_suggestions': suggestions, 'estimated_improvement': f'Potential {len(issues) * 15}% performance improvement'}

    def _assess_maintainability(self, code: str, language: str) -> Dict[str, Any]:
        """Assess code maintainability"""
        score = 100
        factors = {}
        if language == 'python':
            functions = re.findall('def\\s+(\\w+)\\s*\\([^)]*\\):', code)
            long_functions = []
            for func_match in re.finditer('def\\s+\\w+\\s*\\([^)]*\\):(.*?)(?=\\n\\s*def|\\n\\s*class|\\n\\s*@|\\Z)', code, re.DOTALL):
                func_body = func_match.group(1)
                line_count = len(func_body.split('\n'))
                if line_count > 30:
                    long_functions.append(func_match.group(0).split()[1])
                    score -= 10
            factors['long_functions'] = len(long_functions)
        docstring_count = len(re.findall('""".*?"""', code, re.DOTALL))
        total_functions = len(re.findall('\\bdef\\s+\\w+', code))
        docstring_ratio = docstring_count / total_functions if total_functions > 0 else 0
        if docstring_ratio < 0.5:
            score -= 20
            factors['documentation_coverage'] = f'{docstring_ratio:.1%}'
        short_vars = len(re.findall('\\b[a-zA-Z]{1,2}\\b', code))
        if short_vars > 20:
            score -= 5
            factors['short_variable_names'] = short_vars
        return {'maintainability_score': max(0, score), 'grade': self._score_to_grade(score), 'factors': factors}

    def _analyze_complexity(self, code: str, language: str) -> Dict[str, Any]:
        """Analyze code complexity metrics"""
        if language == 'python':
            try:
                tree = ast.parse(code)
                complexity_metrics = {'cyclomatic_complexity': 0, 'nested_depth': 0, 'function_count': 0, 'class_count': 0}
                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        complexity_metrics['function_count'] += 1
                        complexity = 1
                        for child in ast.walk(node):
                            if isinstance(child, (ast.If, ast.For, ast.While, ast.Try)):
                                complexity += 1
                        complexity_metrics['cyclomatic_complexity'] = max(complexity_metrics['cyclomatic_complexity'], complexity)
                    elif isinstance(node, ast.ClassDef):
                        complexity_metrics['class_count'] += 1
                    if isinstance(node, (ast.If, ast.For, ast.While, ast.Try)):
                        depth = 0
                        parent = node
                        while hasattr(parent, 'parent'):
                            if isinstance(parent, (ast.If, ast.For, ast.While, ast.Try)):
                                depth += 1
                            parent = getattr(parent, 'parent', None)
                        complexity_metrics['nested_depth'] = max(complexity_metrics['nested_depth'], depth)
                return complexity_metrics
            except:
                return {'error': 'Could not analyze complexity'}
        return {'language_not_supported': language}

    def _check_best_practices(self, code: str, language: str) -> Dict[str, Any]:
        """Check adherence to best practices"""
        violations = []
        if language == 'python':
            checks = [('\\bif\\s*\\(', 'Missing space after if'), ('\\bfor\\s*\\(', 'Missing space after for'), ('\\bwhile\\s*\\(', 'Missing space after while'), ('^\\s*def\\s+\\w+\\s*\\([^)]*\\)\\s*:\\s*$', 'Missing space before colon in function definition'), ('^\\s*class\\s+\\w+\\s*\\([^)]*\\)\\s*:\\s*$', 'Missing space before colon in class definition'), ('[^\\s]\\s*=\\s*[^=]', 'Incorrect spacing around ='), ('import\\s+os\\s*,\\s*sys', 'Multiple imports on one line')]
            for (pattern, violation) in checks:
                if re.search(pattern, code, re.MULTILINE):
                    violations.append(violation)
        return {'best_practices_violations': len(violations), 'violations': violations, 'compliance_score': max(0, 100 - len(violations) * 10)}

    def _generate_refactoring_suggestions(self, code: str, language: str) -> List[str]:
        """Generate refactoring suggestions"""
        suggestions = []
        if language == 'python':
            functions = re.findall('def\\s+(\\w+)\\s*\\([^)]*\\):(.*?)(?=\\n\\s*def|\\n\\s*class|\\n\\s*@|\\Z)', code, re.DOTALL)
            for func_match in functions:
                (func_name, func_body) = func_match
                if len(func_body.split('\n')) > 50:
                    suggestions.append(f"Break down function '{func_name}' into smaller functions")
            classes = re.findall('class\\s+(\\w+):(.*?)(?=\\n\\s*class|\\Z)', code, re.DOTALL)
            for class_match in classes:
                (class_name, class_body) = class_match
                method_count = len(re.findall('\\s+def\\s+', class_body))
                if method_count > 15:
                    suggestions.append(f"Class '{class_name}' has too many methods ({method_count}). Consider splitting into multiple classes")
            magic_numbers = re.findall('\\b\\d{2,}\\b', code)
            if len(magic_numbers) > 5:
                suggestions.append('Replace magic numbers with named constants')
        return suggestions

    def _suggest_test_coverage(self, code: str, language: str) -> Dict[str, Any]:
        """Suggest test coverage improvements"""
        if language == 'python':
            functions = re.findall('def\\s+(\\w+)\\s*\\([^)]*\\):', code)
            classes = re.findall('class\\s+(\\w+):', code)
            return {'functions_to_test': len(functions), 'classes_to_test': len(classes), 'suggested_tests': [f'Unit tests for {len(functions)} functions', f'Integration tests for {len(classes)} classes', 'Edge case testing for error conditions', 'Performance testing for critical functions'], 'estimated_test_lines': len(functions) * 10 + len(classes) * 20}
        return {'language_not_supported': language}

    def _load_code_patterns(self) -> Dict[str, Any]:
        """Load code patterns for analysis"""
        return {'python': {'function_pattern': 'def\\s+\\w+\\s*\\([^)]*\\):', 'class_pattern': 'class\\s+\\w+.*:', 'import_pattern': '^(?:from\\s+\\w+\\s+)?import\\s+\\w+'}}

    def _load_security_rules(self) -> Dict[str, Any]:
        """Load security analysis rules"""
        return {'dangerous_functions': ['eval', 'exec', 'os.system', 'subprocess.call'], 'unsafe_patterns': ['password\\s*=\\s*.*', 'secret\\s*=\\s*.*']}

    def _load_performance_indicators(self) -> Dict[str, Any]:
        """Load performance analysis indicators"""
        return {'inefficient_patterns': ['for\\s+\\w+\\s+in\\s+range\\(len\\(', '\\+\\s*=\\s*str\\(', '\\.append\\(\\s*\\w+\\s*\\)']}

    def _score_to_grade(self, score: int) -> str:
        """Convert numeric score to letter grade"""
        if score >= 90:
            return 'A'
        elif score >= 80:
            return 'B'
        elif score >= 70:
            return 'C'
        elif score >= 60:
            return 'D'
        else:
            return 'F'

    def _find_line_numbers(self, code: str, pattern: str) -> List[int]:
        """Find line numbers where pattern matches"""
        lines = code.split('\n')
        matches = []
        for (i, line) in enumerate(lines, 1):
            if re.search(pattern, line):
                matches.append(i)
        return matches

    def _generate_quality_recommendations(self, issues: List[str]) -> List[str]:
        """Generate recommendations based on quality issues"""
        recommendations = []
        if any(('long' in issue.lower() for issue in issues)):
            recommendations.append('Break down long functions into smaller, focused functions')
            recommendations.append('Apply Single Responsibility Principle')
        if any(('parameter' in issue.lower() for issue in issues)):
            recommendations.append('Use parameter objects or keyword arguments for functions with many parameters')
        if any(('bare except' in issue.lower() for issue in issues)):
            recommendations.append('Specify exception types in except clauses')
            recommendations.append('Handle specific exceptions rather than catching all')
        if any(('syntax' in issue.lower() for issue in issues)):
            recommendations.append('Fix syntax errors before proceeding')
            recommendations.append('Use a linter like flake8 or pylint')
        if any(('duplicate' in issue.lower() for issue in issues)):
            recommendations.append('Extract duplicate code into reusable functions')
            recommendations.append("Apply DRY (Don't Repeat Yourself) principle")
        return recommendations if recommendations else ['Code quality is generally good']